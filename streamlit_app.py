# –î–æ–±–∞–≤–ª–µ–Ω–Ω—ã–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:
# 1) –ö–Ω–æ–ø–∫–∞ "–°–¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ" –≤–º–µ—Å—Ç–æ –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –ø–æ–ª–∑—É–Ω–∫–æ–≤.
# 2) –î–∏–∞–≥—Ä–∞–º–º–∞ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
# 3) –ï—Å–ª–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –±–æ–ª–µ–∑–Ω–∏ >80%, –≤—ã—Ö–æ–¥–∏—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞—é—â–∏–π —Ç–µ–∫—Å—Ç
# 4) Feature Importance ‚Äì –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
# 5) –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤–≤–æ–¥–∞ ‚Äì –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –∏ –∑–∞–≥—Ä—É–∂–∞—Ç—å –≤–≤–µ–¥–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã.
# 6) –†–µ–∂–∏–º—ã –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ ‚Äì "–ü—Ä–æ—Å—Ç–æ–π" –∏ "–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π" —Ä–µ–∂–∏–º—ã –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞.


import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
import shap
import io

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(page_title="Parkinson's Prediction", layout="centered")

# –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.title("üß† –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –±–æ–ª–µ–∑–Ω–∏ –ü–∞—Ä–∫–∏–Ω—Å–æ–Ω–∞")
st.write("–í–≤–µ–¥–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –∏ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∂–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è.")

# –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∂–∏–º—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
mode = st.sidebar.radio("–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º:", ["–ü—Ä–æ—Å—Ç–æ–π", "–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π"])

# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
file_path = "https://raw.githubusercontent.com/AlexxxAI/HomeWorks/main/parkinsons.data"
df = pd.read_csv(file_path)

df = df.drop(columns=["name"])

st.write("–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")

# –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
correlations = df.corr()["status"].abs().sort_values(ascending=False)
valid_features = [col for col in correlations.index if df[col].nunique() > 10]
top_features = valid_features[:2]  # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –¥–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–∞

# –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
X = df[top_features]
y = df["status"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

# –í—ã–≤–æ–¥ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ –≤—ã–±—Ä–∞–Ω —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Ä–µ–∂–∏–º
if mode == "–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π":
    with st.expander("–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"):
        st.write("**–ü—Ä–∏–∑–Ω–∞–∫–∏ (X)**")
        st.dataframe(X)
        st.write("**–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è (y)**")
        st.dataframe(y)

# –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
logreg_model = LogisticRegression(max_iter=565)
logreg_model.fit(X_train_scaled, y_train)

# –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏
st.sidebar.header("–í–≤–µ–¥–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:")
feature_names = {"spread1": "–†–∞–∑–±—Ä–æ—Å —á–∞—Å—Ç–æ—Ç (spread1)", "PPE": "–î—Ä–æ–∂–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞ (PPE)"}

user_input = {}
for col in X.columns:
    user_input[col] = st.sidebar.slider(feature_names[col], float(df[col].min()), float(df[col].max()), float(df[col].mean()))

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤–≤–æ–¥–∞
if st.sidebar.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤–≤–æ–¥"):
    st.session_state["saved_input"] = user_input
    st.success("–í–≤–æ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω!")

if "saved_input" in st.session_state and st.sidebar.button("üîÑ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π –≤–≤–æ–¥"):
    user_input = st.session_state["saved_input"]
    st.success("–°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")

input_df = pd.DataFrame([user_input])
input_scaled = scaler.transform(input_df)

# –í—ã–≤–æ–¥ –±–ª–æ–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ –≤—ã–±—Ä–∞–Ω —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Ä–µ–∂–∏–º
if mode == "–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π":
    with st.expander("Data Preparation"):
        st.write("**Input Data**")
        st.dataframe(input_df)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–∞–∫ None
prediction = None

# –ö–Ω–æ–ø–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
if st.sidebar.button("–°–¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ"):
    prediction = logreg_model.predict(input_scaled)
    prediction_proba = logreg_model.predict_proba(input_scaled)
    df_prediction_proba = pd.DataFrame(prediction_proba, columns=["–ó–¥–æ—Ä–æ–≤", "–ü–∞—Ä–∫–∏–Ω—Å–æ–Ω"])
    df_prediction_proba = df_prediction_proba.round(2)  # –û–∫—Ä—É–≥–ª—è–µ–º –¥–æ –¥–≤—É—Ö –∑–Ω–∞–∫–æ–≤
    
    st.subheader("üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:")
    
    if prediction[0] == 1:
        st.markdown(
            "<div style='background-color: #ffcccc; padding: 10px; border-radius: 5px;'><strong>‚ö†Ô∏è –í—ã—Å–æ–∫–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –±–æ–ª–µ–∑–Ω–∏ –ü–∞—Ä–∫–∏–Ω—Å–æ–Ω–∞!</strong></div>",
            unsafe_allow_html=True
        )
    else:
        st.success("‚úÖ –ù–∏–∑–∫–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –±–æ–ª–µ–∑–Ω–∏ –ü–∞—Ä–∫–∏–Ω—Å–æ–Ω–∞.")
    
    # –í—ã–≤–æ–¥ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ ProgressColumn
    st.dataframe(
        df_prediction_proba,
        column_config={
            "–ó–¥–æ—Ä–æ–≤": st.column_config.ProgressColumn(
                "–ó–¥–æ—Ä–æ–≤",
                format="%.2f",
                width="medium",
                min_value=0,
                max_value=1
            ),
            "–ü–∞—Ä–∫–∏–Ω—Å–æ–Ω": st.column_config.ProgressColumn(
                "–ü–∞—Ä–∫–∏–Ω—Å–æ–Ω",
                format="%.2f",
                width="medium",
                min_value=0,
                max_value=1
            ),
        },
        hide_index=True
    )
    
    # –í—ã–≤–æ–¥ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞
    parkinson_labels = np.array(["–ó–¥–æ—Ä–æ–≤", "–ü–∞—Ä–∫–∏–Ω—Å–æ–Ω"])
    st.success(f"Predicted status: **{parkinson_labels[prediction][0]}**")
    
    # –ö–Ω–æ–ø–∫–∞ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    csv = df_prediction_proba.to_csv(index=False).encode('utf-8')
    st.download_button("üì• –°–∫–∞—á–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ", data=csv, file_name="prediction.csv", mime="text/csv")

    # SHAP Force Plot
    shap.initjs()
    explainer = shap.Explainer(logreg_model, X_train_scaled)
    shap_values = explainer(input_scaled)
    st.subheader("üìä –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (SHAP)")
    shap_html = shap.force_plot(shap_values.base_values[0], shap_values.values[0], input_df.iloc[0], feature_names=top_features, matplotlib=False)
    st.components.v1.html(shap_html, height=300)

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
st.subheader("üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö")
fig = px.scatter(df, x=top_features[0], y=top_features[1], color="status", title="–î–≤–∞ –Ω–∞–∏–±–æ–ª–µ–µ –∫–æ—Ä—Ä–µ–ª–∏—Ä—É—é—â–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞")
st.plotly_chart(fig)

fig_density = px.density_contour(df, x=top_features[0], y=top_features[1], color="status", title="–ü–ª–æ—Ç–Ω–æ—Å—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö")
st.plotly_chart(fig_density)

fig_hist1 = px.histogram(df, x=top_features[0], nbins=30, title=f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {feature_names[top_features[0]]}")
st.plotly_chart(fig_hist1)
fig_hist2 = px.histogram(df, x=top_features[1], nbins=30, title=f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {feature_names[top_features[1]]}")
st.plotly_chart(fig_hist2)
